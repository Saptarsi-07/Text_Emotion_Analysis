{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"data/text_emotion.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>carefully word blog posts amount criticism hea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cannot remember little mermaid feeling carefre...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>not feeling super well turns cold knocked next...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>feel honored part group amazing talents</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>think helping also began feel pretty lonely lo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  emotion\n",
       "0  carefully word blog posts amount criticism hea...        0\n",
       "1  cannot remember little mermaid feeling carefre...        1\n",
       "2  not feeling super well turns cold knocked next...        1\n",
       "3            feel honored part group amazing talents        1\n",
       "4  think helping also began feel pretty lonely lo...        0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "1    134205\n",
       "0    120334\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balanced data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(254539, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df[['text']]\n",
    "y=df['emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_test split\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_special(text):\n",
    "    clean_text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text)\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_html(text):\n",
    "    pattern=re.compile('<.*?>')\n",
    "    return pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_extra_white_spaces(text):\n",
    "    pattern=r'\\s+[a-zA-Z]\\s+'\n",
    "    without_space=re.sub(pattern=pattern,repl=\" \",string=text)\n",
    "    return without_space\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords=stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "ps=PorterStemmer()\n",
    "def stem_words(text):\n",
    "    return \" \".join([ps.stem(word) for word in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sapta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def remove_stop(text):\n",
    "    new_text=[]\n",
    "    for word in text.split():\n",
    "        if word in stopwords:\n",
    "            new_text.append('')\n",
    "        else:\n",
    "            new_text.append(word)\n",
    "    x=new_text[:]\n",
    "    new_text.clear()\n",
    "    \n",
    "    return \" \".join(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.reset_index()\n",
    "X_test=X_test.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.drop(columns=['index'],axis=1)\n",
    "X_test=X_test.drop(columns=['index'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>feelings victimized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sat chair various times said anything times al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>still challenging feel reassured description son</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>feel sorry people openly slander pass ill judg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>love earlier master presence could feel lot ca...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0                                feelings victimized\n",
       "1  sat chair various times said anything times al...\n",
       "2   still challenging feel reassured description son\n",
       "3  feel sorry people openly slander pass ill judg...\n",
       "4  love earlier master presence could feel lot ca..."
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(X_train):\n",
    "    X_train['text']=X_train['text'].str.lower()\n",
    "    X_train['text']=X_train['text'].apply(remove_special)\n",
    "    X_train['text']=X_train['text'].apply(remove_html)\n",
    "    X_train['text']=X_train['text'].apply(remove_extra_white_spaces)\n",
    "    X_train['text']=X_train['text'].apply(remove_stop)\n",
    "    X_train['text']=X_train['text'].apply(stem_words)\n",
    "\n",
    "    return X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=clean_text(X_train)\n",
    "X_test=clean_text(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>feel victim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sat chair variou time said anyth time alway wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>still challeng feel reassur descript son</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>feel sorri peopl openli slander pass ill judge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>love earlier master presenc could feel lot cas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0                                        feel victim\n",
       "1  sat chair variou time said anyth time alway wa...\n",
       "2           still challeng feel reassur descript son\n",
       "3  feel sorri peopl openli slander pass ill judge...\n",
       "4  love earlier master presenc could feel lot cas..."
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stemmer(object):\n",
    "                def __init__(self):\n",
    "                  self.ps = PorterStemmer()\n",
    "                def __call__(self, text):\n",
    "                  return [self.ps.stem(word) for word in word_tokenize(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipeline=Pipeline(steps=['vectorizer',TfidfVectorizer(analyzer='word',tokenizer=PorterStemmer,max_features=2000)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor=ColumnTransformer([\n",
    "                    ('text_pipeline',text_pipeline,['text'])\n",
    "                    \n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>feel victim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sat chair variou time said anyth time alway wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>still challeng feel reassur descript son</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>feel sorri peopl openli slander pass ill judge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>love earlier master presenc could feel lot cas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203626</th>\n",
       "      <td>felt need share one sentenc found one book del...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203627</th>\n",
       "      <td>posit idea sat feel groggi wait someth chang h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203628</th>\n",
       "      <td>feel quit jolli even though pretti tire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203629</th>\n",
       "      <td>wear shirt feel artist artist look artist ye son</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203630</th>\n",
       "      <td>feel kind mellow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>203631 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text\n",
       "0                                             feel victim\n",
       "1       sat chair variou time said anyth time alway wa...\n",
       "2                still challeng feel reassur descript son\n",
       "3       feel sorri peopl openli slander pass ill judge...\n",
       "4       love earlier master presenc could feel lot cas...\n",
       "...                                                   ...\n",
       "203626  felt need share one sentenc found one book del...\n",
       "203627  posit idea sat feel groggi wait someth chang h...\n",
       "203628            feel quit jolli even though pretti tire\n",
       "203629   wear shirt feel artist artist look artist ye son\n",
       "203630                                   feel kind mellow\n",
       "\n",
       "[203631 rows x 1 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'TfidfVectorizer' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m input_feature_train_arr\u001b[39m=\u001b[39mpreprocessor\u001b[39m.\u001b[39;49mfit_transform(X_train)\u001b[39m.\u001b[39mtoarray()\n\u001b[0;32m      2\u001b[0m input_feature_test_arr\u001b[39m=\u001b[39mpreprocessor\u001b[39m.\u001b[39mtransform(X_test)\u001b[39m.\u001b[39mtoarray()\n",
      "File \u001b[1;32md:\\Text_Emotion_Analysis\\venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32md:\\Text_Emotion_Analysis\\venv\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:723\u001b[0m, in \u001b[0;36mColumnTransformer.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    721\u001b[0m \u001b[39m# set n_features_in_ attribute\u001b[39;00m\n\u001b[0;32m    722\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_n_features(X, reset\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m--> 723\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_transformers()\n\u001b[0;32m    724\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_column_callables(X)\n\u001b[0;32m    725\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_remainder(X)\n",
      "File \u001b[1;32md:\\Text_Emotion_Analysis\\venv\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:407\u001b[0m, in \u001b[0;36mColumnTransformer._validate_transformers\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    405\u001b[0m \u001b[39mif\u001b[39;00m t \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mdrop\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    406\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m--> 407\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mhasattr\u001b[39m(t, \u001b[39m\"\u001b[39m\u001b[39mfit\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mhasattr\u001b[39m(t, \u001b[39m\"\u001b[39m\u001b[39mfit_transform\u001b[39m\u001b[39m\"\u001b[39m)) \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39;49m(\n\u001b[0;32m    408\u001b[0m     t, \u001b[39m\"\u001b[39;49m\u001b[39mtransform\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[0;32m    409\u001b[0m ):\n\u001b[0;32m    410\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    411\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAll estimators should implement fit and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    412\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtransform, or can be \u001b[39m\u001b[39m'\u001b[39m\u001b[39mdrop\u001b[39m\u001b[39m'\u001b[39m\u001b[39m or \u001b[39m\u001b[39m'\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    413\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mspecifiers. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m (type \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (t, \u001b[39mtype\u001b[39m(t))\n\u001b[0;32m    414\u001b[0m     )\n",
      "File \u001b[1;32md:\\Text_Emotion_Analysis\\venv\\lib\\site-packages\\sklearn\\utils\\_available_if.py:32\u001b[0m, in \u001b[0;36m_AvailableIfDescriptor.__get__\u001b[1;34m(self, obj, owner)\u001b[0m\n\u001b[0;32m     26\u001b[0m attr_err \u001b[39m=\u001b[39m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[0;32m     27\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThis \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mrepr\u001b[39m(owner\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m has no attribute \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mrepr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattribute_name)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m     28\u001b[0m )\n\u001b[0;32m     29\u001b[0m \u001b[39mif\u001b[39;00m obj \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     30\u001b[0m     \u001b[39m# delegate only on instances, not the classes.\u001b[39;00m\n\u001b[0;32m     31\u001b[0m     \u001b[39m# this is to allow access to the docstrings.\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheck(obj):\n\u001b[0;32m     33\u001b[0m         \u001b[39mraise\u001b[39;00m attr_err\n\u001b[0;32m     34\u001b[0m     out \u001b[39m=\u001b[39m MethodType(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfn, obj)\n",
      "File \u001b[1;32md:\\Text_Emotion_Analysis\\venv\\lib\\site-packages\\sklearn\\pipeline.py:629\u001b[0m, in \u001b[0;36mPipeline._can_transform\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_can_transform\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 629\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_final_estimator \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mhasattr\u001b[39m(\n\u001b[0;32m    630\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator, \u001b[39m\"\u001b[39m\u001b[39mtransform\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    631\u001b[0m     )\n",
      "File \u001b[1;32md:\\Text_Emotion_Analysis\\venv\\lib\\site-packages\\sklearn\\pipeline.py:309\u001b[0m, in \u001b[0;36mPipeline._final_estimator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[0;32m    308\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_final_estimator\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 309\u001b[0m     estimator \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msteps[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m][\u001b[39m1\u001b[39;49m]\n\u001b[0;32m    310\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m estimator \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m estimator\n",
      "\u001b[1;31mTypeError\u001b[0m: 'TfidfVectorizer' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "input_feature_train_arr=preprocessor.fit_transform(X_train).toarray()\n",
    "input_feature_test_arr=preprocessor.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
